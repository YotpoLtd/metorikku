version: '2'
services:
  zookeeper:
    image: debezium/zookeeper:0.9
  kafka:
    image: debezium/kafka:0.9
    environment:
     KAFKA_CREATE_TOPICS: testAppendOutputMode:1:1
     ZOOKEEPER_CONNECT: zookeeper:2181
     KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
     KAFKA_LISTENERS: PLAINTEXT://kafka:9092
     KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
  mysql:
    image: debezium/example-mysql:0.9
    environment:
     - MYSQL_ROOT_PASSWORD=debezium
     - MYSQL_USER=mysqluser
     - MYSQL_PASSWORD=mysqlpw
     - MYSQL_DATABASE=hive
    volumes:
     - ./scripts/inventory.sql:/docker-entrypoint-initdb.d/inventory.sql
  schema-registry:
    image: confluentinc/cp-schema-registry
    environment:
     - SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL=zookeeper:2181
     - SCHEMA_REGISTRY_HOST_NAME=schema-registry
     - SCHEMA_REGISTRY_LISTENERS=http://schema-registry:8081
    depends_on:
      - mysql
  connect:
    image: debezium/connect:0.9
    environment:
    - BOOTSTRAP_SERVERS=kafka:9092
    - GROUP_ID=1
    - CONFIG_STORAGE_TOPIC=my_connect_configs
    - OFFSET_STORAGE_TOPIC=my_connect_offsets
    - STATUS_STORAGE_TOPIC=my_connect_statuses
    - KEY_CONVERTER=io.confluent.connect.avro.AvroConverter
    - VALUE_CONVERTER=io.confluent.connect.avro.AvroConverter
    - INTERNAL_KEY_CONVERTER=org.apache.kafka.connect.json.JsonConverter
    - INTERNAL_VALUE_CONVERTER=org.apache.kafka.connect.json.JsonConverter
    - CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL=http://schema-registry:8081
    - CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL=http://schema-registry:8081
    depends_on:
      - zookeeper
      - kafka
      - mysql
      - schema-registry
  schema-registry-register:
    image: buildpack-deps:stretch-curl
    volumes:
    - ./scripts:/scripts
    command: /scripts/entrypoint-schema-registry.sh
    depends_on:
      - connect
  mysql-client:
    image: debezium/example-mysql:0.9
    volumes:
    - ./scripts:/scripts
    command: /scripts/entrypoint-mysql-changes.sh
    environment:
      MYSQL_HOST: mysql
      MYSQL_PORT: 3306
      MYSQL_USER: mysqluser
      MYSQL_PASSWORD: mysqlpw
      MAX_RETRIES: 45
    depends_on:
      - mysql
  spark-master:
    image: metorikku/spark
    entrypoint:
    - /scripts/entrypoint-master.sh
    logging:
      driver: none
    depends_on:
      - zookeeper
      - kafka
      - mysql
      - schema-registry
      - connect
      - schema-registry-register
      - mysql-client
  spark-worker:
    image: metorikku/spark
    environment:
    - OUTPUT_EXECUTOR_LOGS_TO_STDOUT=true
    entrypoint:
    - /scripts/entrypoint-worker.sh
    logging:
      driver: none
    depends_on:
    - zookeeper
    - kafka
    - mysql
    - schema-registry
    - connect
    - schema-registry-register
    - mysql-client
    volumes:
    - ../../examples:/examples
    - ./output/:/examples/output/
  spark-submit:
    image: metorikku/metorikku
    environment:
    - SUBMIT_COMMAND=spark-submit --jars https://github.com/YotpoLtd/incubator-hudi/releases/download/0.4.6-snapshot/hoodie-spark-bundle-0.4.6-SNAPSHOT.jar --repositories http://packages.confluent.io/maven/ --packages org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.0,org.apache.kafka:kafka_2.11:0.10.2.2,org.apache.spark:spark-avro_2.11:2.4.0,io.confluent:kafka-avro-serializer:3.3.1 --conf spark.sql.hive.convertMetastoreParquet=false --conf spark.serializer=org.apache.spark.serializer.KryoSerializer --conf spark.sql.catalogImplementation=hive --conf spark.hadoop.hive.metastore.uris=thrift://hive:9083 --conf spark.hadoop.javax.jdo.option.ConnectionURL=jdbc:mysql://mysql:3306/hive?createDatabaseIfNotExist=true&useSSL=false --conf spark.hadoop.javax.jdo.option.ConnectionDriverName=com.mysql.jdbc.Driver --conf spark.hadoop.javax.jdo.option.ConnectionUserName=mysqluser --conf spark.hadoop.javax.jdo.option.ConnectionPassword=mysqlpw --conf spark.sql.warehouse.dir=/warehouse --class com.yotpo.metorikku.Metorikku metorikku.jar -c examples/kafka/kafka_example_cdc.yaml
    - MAX_RETRIES_JOB=3
    entrypoint:
    - /scripts/entrypoint-submit.sh
    volumes:
    - ../../examples:/examples
    - ./output/:/examples/output/
    - ./warehouse:/warehouse
    depends_on:
    - spark-master
    - spark-worker
  hive:
    image: metorikku/hive
    environment:
    - CONNECTION_URL=jdbc:mysql://mysql:3306/hive?useSSL=false
    - CONNECTION_USER_NAME=mysqluser
    - CONNECTION_PASSWORD=mysqlpw
    - WAREHOUSE_DIR=file:///tmp
    - WAIT_HOSTS=mysql:3306
    - MAX_RETRIES=45
    volumes:
    - ./output/:/examples/output/
    - ./scripts:/scripts
    depends_on:
    - mysql
  hive-tester:
    image: metorikku/metorikku
    environment:
    - SUBMIT_COMMAND=spark-submit --jars https://github.com/YotpoLtd/incubator-hudi/releases/download/0.4.6-snapshot/hoodie-spark-bundle-0.4.6-SNAPSHOT.jar --conf spark.sql.hive.convertMetastoreParquet=false --conf spark.serializer=org.apache.spark.serializer.KryoSerializer --conf spark.sql.catalogImplementation=hive --conf spark.hadoop.hive.metastore.uris=thrift://hive:9083 --conf spark.hadoop.javax.jdo.option.ConnectionURL=jdbc:mysql://mysql:3306/hive?createDatabaseIfNotExist=true&useSSL=false --conf spark.hadoop.javax.jdo.option.ConnectionDriverName=com.mysql.jdbc.Driver --conf spark.hadoop.javax.jdo.option.ConnectionUserName=mysqluser --conf spark.hadoop.javax.jdo.option.ConnectionPassword=mysqlpw --conf spark.sql.warehouse.dir=/warehouse --class com.yotpo.metorikku.MetorikkuTester metorikku.jar --test-settings /hive_job/hive_test.yaml
    volumes:
    - ./warehouse:/warehouse
    - ./output/:/examples/output/
    - ./hive_job:/hive_job
    entrypoint:
    - /scripts/entrypoint-submit.sh
    depends_on:
    - spark-master
    - spark-worker
